{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8641ad11-8a5f-40aa-8b78-64816a16df11",
   "metadata": {},
   "source": [
    "# ND2 extractor\n",
    "* An nd2 extractor using the package `nd2` from `https://pypi.org/project/nd2/`.\n",
    "* Supports different dimensions of nd2 files (works fine if there is only one time point or one field of view).\n",
    "* Adjustable threshold for parallelisation to avoid unnecessary `joblib` overheads.\n",
    "* Automatic colour channel identification from metadata.\n",
    "* Human-readable metadata extraction to `.txt` files.\n",
    "* Metadata output in a `.json` format for loading back into your pipeline later as a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89420183-f39f-4261-852e-1eebb7556bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nd2\n",
    "import os\n",
    "from PIL import Image\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4a3cf9-af89-4eb9-bdca-8389681e61b6",
   "metadata": {},
   "source": [
    "## 1. Get metadata\n",
    "* `generate_metadata_txt` outputs a text file with human readable metadata about the experiment.\n",
    "* `generate_metadata_json` outputs a json file with various metadata from your experiment which can be loaded back in as a dictionary at various point of your pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6971eac-385e-48a8-ae91-299e6c8252f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_metadata_txt(nd2_file, outfile):\n",
    "    \"\"\"\n",
    "    Outputs a plain text file summarising the metadata in a human readable format.\n",
    "    \"\"\"\n",
    "    with nd2.ND2File(nd2_file) as ndfile:\n",
    "        with open(outfile, \"w\") as f:\n",
    "            f.write(\"nd2 file is {} \\n\\n\".format(nd2_file))\n",
    "            for key, value in ndfile.text_info.items():\n",
    "                f.write(key)\n",
    "                f.write(\": \\n\\n\")\n",
    "                f.write(value)\n",
    "                f.write(\"\\n\\n\")\n",
    "            f.write(\"Pixel to micron conversion: \\n\")\n",
    "            f.write(\"x voxel size is {} microns/pixel \\n\".format(str(ndfile.voxel_size().x)))\n",
    "            f.write(\"y voxel size is {} microns/pixel \\n\".format(str(ndfile.voxel_size().y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16ed2b3-e375-4e69-87f6-60a7b5b1d458",
   "metadata": {},
   "outputs": [],
   "source": [
    "nd2_file = \"your_file.nd2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbfc08c-3e5a-4291-8cbe-8e13822c2186",
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = \"metadata_nd2_\" + nd2_file.split(\".\")[0] + \".txt\"\n",
    "generate_metadata_txt(nd2_file, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ecdbd8-d8f3-4386-b0d3-cc057c6e381e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_metadata_json(nd2_file, json_outfile, save_file=True):\n",
    "    \"\"\"\n",
    "    Outputs nd2 metadata in a json file which can be loaded back in as a dictionary.\n",
    "    \"\"\"\n",
    "    ##TODO\n",
    "    # laser power setting for each channel (is currently in the text version of metadata)\n",
    "    # exposure time setting for each channel (is currently in the text version of metadata)\n",
    "    # actual time of camera exposure for each image (ask Nikon?)\n",
    "    # actual time of illumination for each image (ask Nikon?)\n",
    "    \n",
    "    nd2_metadata = dict()\n",
    "    with nd2.ND2File(nd2_file) as ndfile:\n",
    "        nd2_metadata[\"file_path\"] = ndfile.path\n",
    "        nd2_metadata[\"shape\"] = ndfile.shape\n",
    "        nd2_metadata[\"ndim\"] = ndfile.ndim\n",
    "        nd2_metadata[\"dtype\"] = str(ndfile.dtype)\n",
    "        nd2_metadata[\"sizes\"] = ndfile.sizes\n",
    "        nd2_metadata[\"is_rgb\"] = ndfile.is_rgb\n",
    "        \n",
    "        FOV_xyz_PFS = dict()\n",
    "        for count, position in enumerate(ndfile.experiment[1].parameters.points):\n",
    "            FOV_xyz_PFS[\"xy{}\".format(str(count).zfill(3))] = (position.stagePositionUm, position.pfsOffset)\n",
    "        nd2_metadata[\"FOV_xyz_PFS_key\"] = {\"FOV_key\": \"([x, y, z], PFS_offset)\"}\n",
    "        nd2_metadata[\"FOV_xyz_PFS\"] = FOV_xyz_PFS\n",
    "        \n",
    "        nd2_metadata[\"axes_order\"] = [\"x\", \"y\", \"z\"]\n",
    "        nd2_metadata[\"axes_calibrated\"] = ndfile.metadata.channels[0].volume.axesCalibrated\n",
    "        nd2_metadata[\"axes_calibration\"] = ndfile.metadata.channels[0].volume.axesCalibration\n",
    "        nd2_metadata[\"FOV_size_in_pixels\"] = ndfile.metadata.channels[0].volume.voxelCount\n",
    "        nd2_metadata[\"microns_per_pixel\"] = float(ndfile.metadata.channels[0].volume.axesCalibration[0])\n",
    "        \n",
    "        nd2_metadata[\"num_timepoints\"] = ndfile.experiment[0].count\n",
    "        nd2_metadata[\"imaging_interval_ms\"] = ndfile.experiment[0].parameters.periodMs\n",
    "        nd2_metadata[\"imaging_interval_ms_mean\"] = ndfile.experiment[0].parameters.periodDiff.avg\n",
    "        nd2_metadata[\"imaging_interval_ms_max\"] = ndfile.experiment[0].parameters.periodDiff.max\n",
    "        nd2_metadata[\"imaging_interval_ms_min\"] = ndfile.experiment[0].parameters.periodDiff.min\n",
    "        \n",
    "        channel_list = []\n",
    "        channel_dict_key = dict()\n",
    "        channel_dict_key[\"channel_name\"] = (\"excitation_wavelength\", \"emission_wavelength\")\n",
    "        channel_lambdas = dict()\n",
    "        for i in range(len(ndfile.metadata.channels)):\n",
    "            channel_list.append(ndfile.metadata.channels[i].channel.name)\n",
    "            channel_lambdas[ndfile.metadata.channels[i].channel.name] = (ndfile.metadata.channels[i].channel.excitationLambdaNm,\n",
    "                                                                         ndfile.metadata.channels[i].channel.emissionLambdaNm)\n",
    "        nd2_metadata[\"channels\"] = channel_list\n",
    "        nd2_metadata[\"channel_wavelengths_key\"] = channel_dict_key\n",
    "        nd2_metadata[\"channel_wavelengths\"] = channel_lambdas\n",
    "        \n",
    "        nd2_metadata[\"objective\"] = ndfile.metadata.channels[0].microscope.objectiveName\n",
    "        nd2_metadata[\"numerical_aperture\"] = ndfile.metadata.channels[0].microscope.objectiveNumericalAperture\n",
    "        nd2_metadata[\"objective_magnification\"] = ndfile.metadata.channels[0].microscope.objectiveMagnification\n",
    "        nd2_metadata[\"post_objective_magnification\"] = ndfile.metadata.channels[0].microscope.zoomMagnification\n",
    "        nd2_metadata[\"immersion_refractive_index\"] = ndfile.metadata.channels[0].microscope.immersionRefractiveIndex\n",
    "        nd2_metadata[\"camera_name\"] = \"Hamamatsu C14440-20UP SN:000470\"\n",
    "        \n",
    "        if save_file:\n",
    "            with open(json_outfile, 'w') as f: \n",
    "                json.dump(nd2_metadata, f)\n",
    "    \n",
    "    return nd2_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b2b87e-188f-46d7-b036-01bc8bb7e1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_outfile = \"metadata_nd2_\" + nd2_file.split(\".\")[0] + \".json\"\n",
    "nd2_metadata = generate_metadata_json(nd2_file, json_outfile, save_file = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0fed19-fbc4-4899-8e23-1b5a55879d1b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Function definitions for nd2 extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29db70fd-9388-4314-95f7-e35264cf8713",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nd2_dimensions(nd2_file):\n",
    "    \"\"\"\n",
    "    Return a dict of the nd2 dimensions. Modifies the .sizes method to give a standardised output.\n",
    "    \"\"\"\n",
    "    with nd2.ND2File(nd2_file) as ndfile:\n",
    "        dimensions = ndfile.sizes\n",
    "        if \"T\" not in dimensions.keys():\n",
    "            dimensions[\"T\"] = 1\n",
    "        if \"P\" not in dimensions.keys():\n",
    "            dimensions[\"P\"] = 1\n",
    "        if \"C\" not in dimensions.keys():\n",
    "            dimensions[\"C\"] = 1\n",
    "        \n",
    "        return dict(sorted(dimensions.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed7b7da-eb82-4a6c-8915-5a00b08ccc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_channel_dict(nd2_file):\n",
    "    \"\"\"\n",
    "    Returns a dictionary mapping the channel index to the channel name (colour)\n",
    "    \"\"\"\n",
    "    channels = {}\n",
    "    with nd2.ND2File(nd2_file) as ndfile:\n",
    "        for i in range(len(ndfile.metadata.channels)): \n",
    "            channels[str(i)] = ndfile.metadata.channels[i].channel.name\n",
    "    \n",
    "    return channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8b739d-ba0d-48c1-8016-d1ad7b42c003",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_joblib_packages(dimensions, parallelisation_min = 50, njobs_max = 16):\n",
    "    \"\"\"\n",
    "    Split the largest dimension into packages to be parallelised along.\n",
    "    Packages will be supplied as a nested list, with len(packages) = njobs\n",
    "    \"\"\"\n",
    "    \n",
    "    all_frames = []\n",
    "    for p in range(dimensions[\"P\"]):\n",
    "        for c in range(dimensions[\"C\"]):\n",
    "            for t in range(dimensions[\"T\"]):\n",
    "                all_frames.append((p,c,t))\n",
    "    \n",
    "    ## if nd2 is small, it is better to avoid joblib overhead ##\n",
    "    if dimensions[\"T\"] * dimensions[\"P\"] * dimensions[\"C\"] < parallelisation_min:\n",
    "        njobs = 1\n",
    "    else:\n",
    "        njobs = njobs_max\n",
    "        \n",
    "    #####     \n",
    "    \n",
    "    num_imgs = dimensions[\"P\"] * dimensions[\"T\"] * dimensions[\"C\"]\n",
    "    package_length = int(num_imgs/njobs)\n",
    "    \n",
    "    nd2_indices_dict = dict()\n",
    "    FOV_counter = 0\n",
    "    t_counter = 0\n",
    "    ch_counter = 0\n",
    "    for x in range(num_imgs):\n",
    "        nd2_indices_dict[x] = [FOV_counter, t_counter, ch_counter]\n",
    "        ch_counter = ch_counter + 1\n",
    "        if ch_counter >= dimensions[\"C\"]:\n",
    "            ch_counter = 0\n",
    "            t_counter = t_counter + 1\n",
    "            if t_counter >= dimensions[\"T\"]:\n",
    "                t_counter = 0\n",
    "                FOV_counter = FOV_counter + 1\n",
    "                    \n",
    "    packages = np.linspace(0, num_imgs, njobs, endpoint=False)\n",
    "    indices = [int(x) for x in packages]\n",
    "    indices[0] = 0\n",
    "    \n",
    "    # seems to fix it for njobs=1\n",
    "    if njobs > 1:\n",
    "        indices[-1] = len(nd2_indices_dict) - (package_length + 1)\n",
    "    else:\n",
    "        indices[-1] = len(nd2_indices_dict) - (package_length)\n",
    "        \n",
    "    joblib_packages = []\n",
    "    for count, idx in enumerate(indices):\n",
    "        if count <= len(indices)-2:\n",
    "            # package = list(range(idx,indices[count+1]))\n",
    "            package = all_frames[idx:indices[count+1]]\n",
    "        else:\n",
    "            # package = list(range(idx,idx+package_length+1))\n",
    "            package = all_frames[idx:idx+package_length+1]\n",
    "        joblib_packages.append(package)\n",
    "    \n",
    "    return njobs, joblib_packages, all_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5594f313-a89e-4f1c-9155-ea8b75dc6d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_png(numpy_array, channels, p, c, t, save_dir):\n",
    "    im = Image.fromarray(numpy_array)\n",
    "    im.save(\"{}/xy{}_{}_T{}.png\".format(save_dir, str(p).zfill(3), channels[str(c)], str(t).zfill(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87b6655-302f-46e4-b0e6-5dea0ce06c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pngs(dask_array, save_dir, dimensions, channels, package):\n",
    "    \"\"\"\n",
    "    Extract all png files from a package.\n",
    "    \"\"\"\n",
    "    \n",
    "    for tup in tqdm(package):\n",
    "        p,c,t = tup\n",
    "        \n",
    "        ## based on nd2 dimensions, index dask array appropriately ##\n",
    "        if dimensions[\"T\"] != 1 and dimensions[\"P\"] != 1 and dimensions[\"C\"] != 1:\n",
    "            arr = np.array(dask_array[t,p,c,:,:])\n",
    "            save_png(arr, channels, p, c, t, save_dir)\n",
    "        elif dimensions[\"T\"] == 1 and dimensions[\"P\"] == 1:\n",
    "            arr = np.array(dask_array[c,:,:])\n",
    "            save_png(arr, channels, p, c, t, save_dir)\n",
    "        elif dimensions[\"T\"] == 1 and dimensions[\"C\"] == 1:\n",
    "            arr = np.array(dask_array[p,:,:])\n",
    "            save_png(arr, channels, p, c, t, save_dir)\n",
    "        elif dimensions[\"P\"] == 1 and dimensions[\"C\"] == 1:\n",
    "            arr = np.array(dask_array[t,:,:])\n",
    "            save_png(arr, channels, p, c, t, save_dir)\n",
    "        elif dimensions[\"T\"] == 1:\n",
    "            arr = np.array(dask_array[p,c,:,:])\n",
    "            save_png(arr, channels, p, c, t, save_dir)\n",
    "        elif dimensions[\"P\"] == 1:\n",
    "            arr = np.array(dask_array[t,c,:,:])\n",
    "            save_png(arr, channels, p, c, t, save_dir)\n",
    "        elif dimensions[\"C\"] == 1:\n",
    "            arr = np.array(dask_array[t,p,:,:])\n",
    "            save_png(arr, channels, p, c, t, save_dir)\n",
    "        \n",
    "        else:\n",
    "            arr = np.array(dask_array[:,:])\n",
    "            save_png(arr, channels, p, c, t, save_dir)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd61a4c2-5ddd-41b3-8dd6-12babb145672",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_all_pngs(nd2_file, save_dir, dimensions, channels, njobs, packages, backend=\"loky\"):\n",
    "    \"\"\"\n",
    "    Extract all png files from the nd2.\n",
    "    \"\"\"\n",
    "    \n",
    "    ## create a save folder ##\n",
    "    try:\n",
    "        os.mkdir(save_dir)\n",
    "    except:\n",
    "        print(\"Target save directory already exists!\")\n",
    "        pass\n",
    "    \n",
    "    ## generate dask array from nd2 file ##\n",
    "    dask_array = nd2.imread(nd2_file, dask=True)\n",
    "    \n",
    "    ## extract pngs from nd2 file, avoiding joblib overhead for small jobs ##\n",
    "    if njobs == 1:\n",
    "        for package in packages:\n",
    "            extract_pngs(dask_array, save_dir, dimensions, channels, package)\n",
    "            \n",
    "    ## parallelise for big jobs ##\n",
    "    else:\n",
    "        Parallel(n_jobs=njobs, backend=backend)(delayed(extract_pngs)(dask_array, save_dir, dimensions, channels, package) for package in tqdm(packages))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e02e9a-ff66-4acb-a371-f4066f8af8b4",
   "metadata": {},
   "source": [
    "## 3. Extract all pngs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f962087-2598-4403-a67c-9787e701f6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = \"extracted\"\n",
    "dimensions = get_nd2_dimensions(nd2_file)\n",
    "channels = get_channel_dict(nd2_file)\n",
    "njobs, packages, all_frames = create_joblib_packages(dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187bce4e-abd5-4c9c-aad2-8d16441a4066",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_all_pngs(nd2_file, save_dir, dimensions, channels, njobs, packages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7509cb-fe29-47e2-bf27-236884089cf1",
   "metadata": {},
   "source": [
    "## 4. Additional metadata\n",
    "* `temporal_frame_spacing` outputs a graph showing the consistency of the frame spacing in different channels\n",
    "    * TODO: Plot all colour channels on same graph in `temporal_frame_spacing`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5d1dfa-7d50-4565-aa24-1ff28dd4f573",
   "metadata": {},
   "outputs": [],
   "source": [
    "def temporal_frame_spacing(nd2_file, dimensions, channel=0, channels=None, outfile=None):\n",
    "    \"\"\"\n",
    "    Plots the temporal frame spacing of a single colour channel.\n",
    "    \"\"\"\n",
    "    frame_timings = []\n",
    "    with nd2.ND2File(nd2_file) as f:\n",
    "        for frame in range(channel,f.metadata.contents.frameCount,int(f.metadata.contents.frameCount/dimensions[\"T\"])):\n",
    "            frame_timings.append(f.frame_metadata(frame).channels[channel].time.relativeTimeMs/1000)\n",
    "        \n",
    "        single_channel_frame_list = list(range(channel,f.metadata.contents.frameCount,int(f.metadata.contents.frameCount/dimensions[\"T\"]))) # if you want to plot frame number instead of time point\n",
    "        frame_spacing = np.diff(frame_timings).tolist()\n",
    "        time_points = list(range(len(frame_spacing)))\n",
    "        \n",
    "        if outfile:\n",
    "            mean_frame_spacing = np.mean(frame_spacing)\n",
    "            CV_frame_spacing = np.std(frame_spacing)/mean_frame_spacing\n",
    "            with open(outfile, 'a') as f:\n",
    "                f.write(\"\\n\")\n",
    "                f.write(\"The mean temporal frame spacing in the {} channel is {}s and the coefficient of variation in the frame spacing is {}\".format(channels[str(channel)], str(round(mean_frame_spacing, 4)), str(round(CV_frame_spacing, 5))))\n",
    "        \n",
    "        plt.plot(time_points, frame_spacing)\n",
    "        plt.xlabel(\"Time point (-)\")\n",
    "        plt.ylabel(\"Frame spacing (s)\")\n",
    "        if channels:\n",
    "            plt.title(\"Temporal frame spacing in {} channel\".format(channels[str(channel)]))\n",
    "        else:\n",
    "            plt.title(\"Temporal frame spacing in channel {}\".format(str(channel)))\n",
    "        \n",
    "        plt.savefig(\"{}_{}_channel_temporal_frame_spacing.png\".format(nd2_file.split(\".\")[0], channels[str(channel)]), bbox_inches='tight', dpi=250)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add7c1a4-b438-45d6-988e-52933eed9030",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(channels)):\n",
    "    temporal_frame_spacing(nd2_file, dimensions, channel=i, channels=channels, outfile=outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9c188c-ae5d-423c-a81b-dbd78a547ec7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
